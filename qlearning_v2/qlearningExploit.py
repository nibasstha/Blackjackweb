from blackjack import Blackjack

import numpy as np

import numpy as np

import copy

normal_hands_table = np.load('normal_hands_table_v4.npy',allow_pickle=True)
usable_ace_hands_table = np.load('usable_ace_hands_table_v4.npy',allow_pickle=True)
same_value_hands_table = np.load('same_value_hands_table_v4.npy',allow_pickle=True)

action_idx_to_action = {
  0:"stand",
  1:'hit',
  2:'double',
  3:"split"
}




def qlearningExploit():
  game = Blackjack(3)
  win = 0
  loss = 0
  draw = 0
  non_res = 0

  for episode in range(500):
    print("episode",episode)
    game.start_game()
    status = game.check_blackjack()

    if status == 'player_blackjack':
      print("Player won without doing anything !!")
    else:
      while status == 'continue':
        current_player_turn = copy.deepcopy(game.current_turn)
        state = copy.deepcopy(game.get_current_state(current_player_turn))

        print("checking tablw")

        if 'split' in state['valid_actions'] and state["split_hand_possible"]:
          action_idx = same_value_hands_table[state["split_hand_player_idx"],state["dealer_idx"],state["true_count"]].argmax()
        elif state["has_usable_ace"]:
          action_idx = usable_ace_hands_table[state["usable_ace_player_idx"],state["dealer_idx"],state["true_count"],state["play_idx"]].argmax()
        else:
          action_idx = normal_hands_table[state["normal_hand_player_idx"],state["dealer_idx"],state["true_count"],state["play_idx"]].argmax()

      
        # print("action_idx is",action_idx)
        action = action_idx_to_action[action_idx]

        # action = np.random.choice(state["valid_actions"])

        status = game.player_action(action)

        new_state = copy.deepcopy(game.get_current_state(current_player_turn))

        state_with_action = copy.deepcopy(game.get_current_state(current_player_turn,action))


        print("--------------")
        print("state before action",state)
        print("state with action included",state_with_action)
        print("state after action",new_state)
        print("--------------")

        if action == 'stand':
          if(len(game.player_cards[1])==0):
            break
          else:
            if(game.current_turn == 'playerFirstHand'):
              game.current_turn = 'playerSecondHand'
              status = 'continue'
            else:
              break
      
      final_result = game.game_result()
      iterable_result = game.iterable_game_result()
      print('iterable res',iterable_result)
      for result in iterable_result:
        if result != None :
          if result == 'win':
            win = win +1
          if result == 'loss' or result == 'bust':
            loss = loss +1
          if result == 'draw':
            draw = draw +1
        else:
          non_res = non_res + 1

  print("Final win",win)
  print("Final Loss",loss)
  print("Final draw",draw)
  print("final no res",non_res)
  print("win rate",(win/(win+loss))*100)

if __name__ == '__main__':
  qlearningExploit()